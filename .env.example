# Copy to .env and adjust. Do not commit .env.

# --- Paths ---
# Project root (use forward slashes). Data lives under BASE_PATH/data.
BASE_PATH=F:/AI-toolkit
# Optional: override data directory
# DATA_PATH=F:/AI-toolkit/data

# --- Open WebUI ---
# Auth: True = login required (group/Tailscale). False = single-user local only.
# WEBUI_AUTH=True
# Use model gateway for unified models (recommended)
# OPENAI_API_BASE=http://model-gateway:11435/v1

# --- Ollama ---
# Models to pull on first start (comma-separated). Use profile: docker compose --profile models up
MODELS=deepseek-r1:7b,deepseek-coder:6.7b,nomic-embed-text

# --- Model Gateway ---
# Port on host (default 11435). Gateway caches model list for MODEL_CACHE_TTL_SEC.
# MODEL_GATEWAY_PORT=11435
# MODEL_CACHE_TTL_SEC=60
# Optional: add vLLM; set when using --profile vllm
# VLLM_URL=http://vllm:8000
# VLLM_MODEL=meta-llama/Llama-3.2-3B-Instruct

# --- Ops Controller ---
# Required for dashboard start/stop/restart/logs. Generate: openssl rand -hex 32
# OPS_CONTROLLER_TOKEN=
# Optional: rotate audit log when it exceeds this size (default 10485760 = 10MB)
# AUDIT_LOG_MAX_BYTES=10485760

# --- Dashboard ---
# Optional: require Bearer token or Basic password for dashboard API (Tailscale/group use)
# DASHBOARD_AUTH_TOKEN=
# DASHBOARD_PASSWORD=

# --- OpenClaw ---
# Gateway auth (pinned; change only if re-pairing all devices). Generate: openssl rand -hex 32
# OPENCLAW_GATEWAY_TOKEN=
# Optional: override config/workspace paths
# OPENCLAW_CONFIG_DIR=%BASE_PATH%/data/openclaw
# OPENCLAW_WORKSPACE_DIR=%BASE_PATH%/data/openclaw/workspace
# OPENCLAW_GATEWAY_PORT=18789
# OPENCLAW_BRIDGE_PORT=18790

# --- MCP Gateway ---
# Servers to enable (comma-separated). See mcp/README.md and data/mcp/registry.json.
# MCP_GATEWAY_SERVERS=duckduckgo
# MCP_GATEWAY_PORT=8811

# --- Compute (optional) ---
# Auto-set by scripts/detect_hardware.py. Or set: nvidia, amd, intel, cpu
# COMPUTE_MODE=nvidia
# COMPOSE_FILE=docker-compose.yml;docker-compose.compute.yml

# --- vLLM profile ---
# When using: docker compose -f docker-compose.yml -f docker-compose.vllm.yml --profile vllm up -d
# set in .env: VLLM_URL=http://vllm:8000 and restart model-gateway.
